{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to D:\\Portfolio Github\\Airport_Chatbot\\data\\silver\\processed_changi_data.json\n",
      "Processed data saved to D:\\Portfolio Github\\Airport_Chatbot\\data\\silver\\processed_jewel_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_text(text_list):\n",
    "    \"\"\"\n",
    "    Cleans the text by removing empty strings, repetitive phrases, and irrelevant content.\n",
    "    \n",
    "    Parameters:\n",
    "        text_list (list): A list of strings containing text extracted from web pages.\n",
    "    \n",
    "    Returns:\n",
    "        list: A cleaned list of strings with irrelevant content removed and duplicates handled.\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for text in text_list:\n",
    "        # Skip text that contains navigation phrases, copyright notices, or irrelevant content\n",
    "        if re.search(r'(Conditions of Use|Privacy Policy|Â©|Back|Download App|Sign Up)', text, re.IGNORECASE):\n",
    "            continue\n",
    "        # Skip empty strings or strings that are too short to be meaningful\n",
    "        if not text.strip() or len(text.strip()) < 3:\n",
    "            continue\n",
    "        # Add the text to the cleaned list only if it's not already included\n",
    "        if text not in cleaned:\n",
    "            cleaned.append(text.strip())\n",
    "    return cleaned\n",
    "\n",
    "def process_json(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Processes an input JSON file to clean and organize the content.\n",
    "    \n",
    "    Parameters:\n",
    "        input_file (str): Path to the input JSON file containing scraped data.\n",
    "        output_file (str): Path to the output JSON file where cleaned data will be saved.\n",
    "    \"\"\"\n",
    "    # Open and read the input JSON file\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        data = json.load(infile)\n",
    "    \n",
    "    cleaned_data = {}\n",
    "    \n",
    "    # Iterate over each URL and its associated content\n",
    "    for url, content in data.items():\n",
    "        # Clean the content for the current URL\n",
    "        cleaned_content = clean_text(content)\n",
    "        # Add the cleaned content to the dictionary only if it's not empty\n",
    "        if cleaned_content:\n",
    "            cleaned_data[url] = cleaned_content\n",
    "    \n",
    "    # Write the cleaned data to the output JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(cleaned_data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Processed data saved to {output_file}\")\n",
    "\n",
    "# Paths to the input and output JSON files for the first dataset\n",
    "changi_input = r\"D:\\Portfolio Github\\Airport_Chatbot\\data\\bronze\\changi_data.json\"\n",
    "changi_output = r\"D:\\Portfolio Github\\Airport_Chatbot\\data\\silver\\processed_changi_data.json\"\n",
    "\n",
    "# Paths to the input and output JSON files for the second dataset\n",
    "jewel_input = r\"D:\\Portfolio Github\\Airport_Chatbot\\data\\bronze\\jewel_data.json\"\n",
    "jewel_output = r\"D:\\Portfolio Github\\Airport_Chatbot\\data\\silver\\processed_jewel_data.json\"\n",
    "\n",
    "# Process the first JSON file (Changi data)\n",
    "process_json(changi_input, changi_output)\n",
    "\n",
    "# Process the second JSON file (Jewel data)\n",
    "process_json(jewel_input, jewel_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
